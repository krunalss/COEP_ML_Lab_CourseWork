# -*- coding: utf-8 -*-
"""ML_lab_assign2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13kOuIvLx8L29TYP9UKsP6hciC48VYzYP
"""

#Importing & Loading Dataset Linnerud dataset

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.datasets import load_linnerud
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.pipeline import Pipeline

sns.set(style="whitegrid")

# Load dataset as pandas DataFrames
linnerud = load_linnerud(as_frame=True)
X_full = linnerud.data          # features: Chins, Situps, Jumps
Y_full = linnerud.target        # targets: Weight, Waist, Pulse

df = pd.concat([X_full, Y_full], axis=1)

print("Feature columns:", X_full.columns.tolist())
print("Target columns:", Y_full.columns.tolist())
df.head()

#Preprocessing data and showing


print("Dataset shape:", df.shape)
print("\nMissing values per column:\n", df.isna().sum())

print("\nSummary statistics:\n")
display(df.describe())

print("\nFeatures (X):")
display(X_full.head())

print("\nTargets (Y):")
display(Y_full.head())

#Extracting features and targets



X = X_full.copy()
y = Y_full["Weight"]                 # single target
Y_multi = Y_full[["Weight", "Waist"]]  # two targets for multi-output regression

print("X shape:", X.shape)
print("y (Weight) shape:", y.shape)

# Multi-target (for true multivariate regression): Weight and Waist
print("Y_multi (Weight & Waist) shape:", Y_multi.shape)

#Correlation of each feature with target "Weight"

df_corr = pd.concat([X, y], axis=1)   # features + Weight
corr_matrix = df_corr.corr(numeric_only=True)

print("Full correlation matrix:")
display(corr_matrix)

target_corr = corr_matrix["Weight"].drop("Weight").sort_values(ascending=False)

print("\nCorrelation of each feature with Weight (sorted):")
print(target_corr)

target_corr  #display

#Visualizing feature–target correlations (Weight)

plt.figure(figsize=(6, 4))
sns.barplot(
    x=target_corr.values,
    y=target_corr.index
)
plt.xlabel("Correlation with Weight")
plt.ylabel("Feature")
plt.title("Linnerud: Feature–Weight Correlations")
plt.tight_layout()
plt.show()

# Selecting subset of features based on correlation strength

top_k = 5
k = min(top_k, len(X.columns))  # in this dataset k becomes 3

selected_features = (
    target_corr.abs()
    .sort_values(ascending=False)
    .head(k)
    .index
    .tolist()
)

print(f"Selected features (top {k} by |corr| with Weight):")
for f in selected_features:
    print(f"  {f}: corr = {target_corr[f]:.4f}")

X_subset = X[selected_features]

print("\nShape of X_subset:", X_subset.shape)
X_subset.head()

#Baseline Linear Regression (subset features -> Weight)

X_train_sub, X_test_sub, y_train_sub, y_test_sub = train_test_split(
    X_subset, y, test_size=0.3, random_state=42
)

# Scale features
scaler_sub = StandardScaler()
X_train_sub_scaled = scaler_sub.fit_transform(X_train_sub)
X_test_sub_scaled = scaler_sub.transform(X_test_sub)

# Baseline linear regression
lin_reg = LinearRegression()
lin_reg.fit(X_train_sub_scaled, y_train_sub)

y_train_pred_lin = lin_reg.predict(X_train_sub_scaled)
y_test_pred_lin = lin_reg.predict(X_test_sub_scaled)

# Train metrics
mse_train_lin = mean_squared_error(y_train_sub, y_train_pred_lin)
rmse_train_lin = np.sqrt(mse_train_lin)
mae_train_lin = mean_absolute_error(y_train_sub, y_train_pred_lin)
r2_train_lin = r2_score(y_train_sub, y_train_pred_lin)

# Test metrics
mse_test_lin = mean_squared_error(y_test_sub, y_test_pred_lin)
rmse_test_lin = np.sqrt(mse_test_lin)
mae_test_lin = mean_absolute_error(y_test_sub, y_test_pred_lin)
r2_test_lin = r2_score(y_test_sub, y_test_pred_lin)

print("=== Baseline Linear Regression (subset features -> Weight) ===")
print("Train:")
print(f"  MSE : {mse_train_lin:.4f}")
print(f"  RMSE: {rmse_train_lin:.4f}")
print(f"  MAE : {mae_train_lin:.4f}")
print(f"  R2  : {r2_train_lin:.4f}")
print("Test:")
print(f"  MSE : {mse_test_lin:.4f}")
print(f"  RMSE: {rmse_test_lin:.4f}")
print(f"  MAE : {mae_test_lin:.4f}")
print(f"  R2  : {r2_test_lin:.4f}")

#Polynomial Linear Regression (degree=2, subset features -> Weight)

poly = PolynomialFeatures(degree=2, include_bias=False)

X_train_poly = poly.fit_transform(X_train_sub_scaled)
X_test_poly = poly.transform(X_test_sub_scaled)

poly_reg = LinearRegression()
poly_reg.fit(X_train_poly, y_train_sub)

y_train_pred_poly = poly_reg.predict(X_train_poly)
y_test_pred_poly = poly_reg.predict(X_test_poly)

# Train metrics
mse_train_poly = mean_squared_error(y_train_sub, y_train_pred_poly)
rmse_train_poly = np.sqrt(mse_train_poly)
mae_train_poly = mean_absolute_error(y_train_sub, y_train_pred_poly)
r2_train_poly = r2_score(y_train_sub, y_train_pred_poly)

# Test metrics
mse_test_poly = mean_squared_error(y_test_sub, y_test_pred_poly)
rmse_test_poly = np.sqrt(mse_test_poly)
mae_test_poly = mean_absolute_error(y_test_sub, y_test_pred_poly)
r2_test_poly = r2_score(y_test_sub, y_test_pred_poly)

print("Number of polynomial features:", X_train_poly.shape[1])

print("\n=== Polynomial Regression (degree=2, subset features -> Weight) ===")
print("Train:")
print(f"  MSE : {mse_train_poly:.4f}")
print(f"  RMSE: {rmse_train_poly:.4f}")
print(f"  MAE : {mae_train_poly:.4f}")
print(f"  R2  : {r2_train_poly:.4f}")
print("Test:")
print(f"  MSE : {mse_test_poly:.4f}")
print(f"  RMSE: {rmse_test_poly:.4f}")
print(f"  MAE : {mae_test_poly:.4f}")
print(f"  R2  : {r2_test_poly:.4f}")

#Multivariate (multi-output) regression with two targets: Weight & Waist

Y_two = Y_multi[["Weight", "Waist"]]

X_train_m, X_test_m, Y_train_m, Y_test_m = train_test_split(
    X_subset, Y_two, test_size=0.3, random_state=42
)

# Scale features
scaler_m = StandardScaler()
X_train_m_scaled = scaler_m.fit_transform(X_train_m)
X_test_m_scaled = scaler_m.transform(X_test_m)

multi_reg = LinearRegression()
multi_reg.fit(X_train_m_scaled, Y_train_m)

Y_train_pred_m = multi_reg.predict(X_train_m_scaled)
Y_test_pred_m = multi_reg.predict(X_test_m_scaled)

# Metrics per target
mse_train_m = mean_squared_error(Y_train_m, Y_train_pred_m, multioutput='raw_values')
mse_test_m = mean_squared_error(Y_test_m, Y_test_pred_m, multioutput='raw_values')
r2_train_m = r2_score(Y_train_m, Y_train_pred_m, multioutput='raw_values')
r2_test_m = r2_score(Y_test_m, Y_test_pred_m, multioutput='raw_values')

print("=== Multi-output Linear Regression (subset features -> Weight & Waist) ===")
for i, target_name in enumerate(Y_two.columns):
    print(f"\nTarget: {target_name}")
    print(f"  Train MSE: {mse_train_m[i]:.4f}")
    print(f"  Train R2 : {r2_train_m[i]:.4f}")
    print(f"  Test  MSE: {mse_test_m[i]:.4f}")
    print(f"  Test  R2 : {r2_test_m[i]:.4f}")

#Hyperparameter tuning on Baseline Linear model (Ridge, subset features -> Weight)

baseline_pipeline = Pipeline([
    ("scaler", StandardScaler()),
    ("ridge", Ridge())
])

param_grid_baseline = {
    "ridge__alpha": [0.01, 0.1, 1.0, 10.0, 100.0]
}

grid_baseline = GridSearchCV(
    estimator=baseline_pipeline,
    param_grid=param_grid_baseline,
    scoring="neg_mean_squared_error",
    cv=5
)

grid_baseline.fit(X_subset, y)

print("=== Hyperparameter tuning: Baseline Linear (Ridge) ===")
print("Best params:", grid_baseline.best_params_)
print("Best CV MSE:", -grid_baseline.best_score_)

best_baseline_model = grid_baseline.best_estimator_

#Hyperparameter tuning on Polynomial Regression (degree + Ridge alpha)

poly_pipeline = Pipeline([
    ("scaler", StandardScaler()),
    ("poly", PolynomialFeatures(include_bias=False)),
    ("ridge", Ridge())
])

param_grid_poly = {
    "poly__degree": [1, 2, 3],
    "ridge__alpha": [0.01, 0.1, 1.0, 10.0]
}

grid_poly = GridSearchCV(
    estimator=poly_pipeline,
    param_grid=param_grid_poly,
    scoring="neg_mean_squared_error",
    cv=5
)

grid_poly.fit(X_subset, y)

print("=== Hyperparameter tuning: Polynomial + Ridge ===")
print("Best params:", grid_poly.best_params_)
print("Best CV MSE:", -grid_poly.best_score_)

best_poly_model = grid_poly.best_estimator_

# Cell 12: Hyperparameter tuning on Multivariate regression (two targets: Weight & Waist)

from sklearn.pipeline import Pipeline
from sklearn.linear_model import Ridge
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score

# We already have:
# X_subset  -> selected input features
# Y_two     -> Y_multi[["Weight", "Waist"]]

X_train_m, X_test_m, Y_train_m, Y_test_m = train_test_split(
    X_subset, Y_two, test_size=0.3, random_state=42
)

# Pipeline: scaling + Ridge (supports multi-output directly)
multi_pipeline = Pipeline([
    ("scaler", StandardScaler()),
    ("ridge", Ridge())
])

# Hyperparameters to tune
param_grid_multi = {
    "ridge__alpha": [0.01, 0.1, 1.0, 10.0, 100.0]
}

# Grid search with CV
grid_multi = GridSearchCV(
    estimator=multi_pipeline,
    param_grid=param_grid_multi,
    scoring="neg_mean_squared_error",  # averaged over both targets
    cv=5
)

grid_multi.fit(X_train_m, Y_train_m)

print("=== Hyperparameter tuning: Multi-output Ridge (Weight & Waist) ===")
print("Best params:", grid_multi.best_params_)
print("Best CV MSE:", -grid_multi.best_score_)

best_multi_model = grid_multi.best_estimator_

# Evaluate best model on test set
Y_test_pred_best = best_multi_model.predict(X_test_m)

mse_test_multi = mean_squared_error(Y_test_m, Y_test_pred_best, multioutput='raw_values')
r2_test_multi = r2_score(Y_test_m, Y_test_pred_best, multioutput='raw_values')

print("\n=== Test performance of best multi-output model ===")
for i, target_name in enumerate(Y_two.columns):
    print(f"\nTarget: {target_name}")
    print(f"  Test MSE: {mse_test_multi[i]:.4f}")
    print(f"  Test R2 : {r2_test_multi[i]:.4f}")

#RMSE of Base vs Tuned Models

#RMSE for tuned Baseline Linear (Weight)
y_test_pred_lin_tuned = best_baseline_model.predict(X_test_sub)  # Pipeline: scaler + Ridge
mse_test_lin_tuned = mean_squared_error(y_test_sub, y_test_pred_lin_tuned)
rmse_test_lin_tuned = np.sqrt(mse_test_lin_tuned)

# RMSE for tuned Polynomial + Ridge (Weight)
y_test_pred_poly_tuned = best_poly_model.predict(X_test_sub)     # Pipeline: scaler + poly + Ridge
mse_test_poly_tuned = mean_squared_error(y_test_sub, y_test_pred_poly_tuned)
rmse_test_poly_tuned = np.sqrt(mse_test_poly_tuned)

# RMSE for base multi-output (Weight & Waist)
rmse_test_multi_base = np.sqrt(mse_test_m)

#RMSE for tuned multi-output (Weight & Waist)
rmse_test_multi_tuned = np.sqrt(mse_test_multi)

models = [
    "Linear (Weight)",
    "Polynomial (Weight)",
    "Multi-out Weight",
    "Multi-out Waist"
]

rmse_base = [
    rmse_test_lin,              # from baseline single-output model
    rmse_test_poly,             # from baseline polynomial model
    rmse_test_multi_base[0],    # base multi-output, target: Weight
    rmse_test_multi_base[1],    # base multi-output, target: Waist
]

rmse_tuned = [
    rmse_test_lin_tuned,        # tuned baseline (Ridge)
    rmse_test_poly_tuned,       # tuned polynomial + Ridge
    rmse_test_multi_tuned[0],   # tuned multi-output, target: Weight
    rmse_test_multi_tuned[1],   # tuned multi-output, target: Waist
]

x = np.arange(len(models))
width = 0.35

plt.figure(figsize=(10, 6))
plt.bar(x - width/2, rmse_base, width, label="Base")
plt.bar(x + width/2, rmse_tuned, width, label="Tuned")

plt.xticks(x, models, rotation=15)
plt.ylabel("RMSE")
plt.title("RMSE Comparison – Base vs Tuned Models")
plt.legend()
plt.tight_layout()
plt.show()

#Regression line for tuned Baseline Linear (Weight vs one feature)

feature_to_plot = selected_features[0]  # first feature from correlation-based selection

print("Feature used for regression line plot:", feature_to_plot)

x_all = X_subset[feature_to_plot].values
y_all = y.values  # Weight


x_grid = np.linspace(x_all.min(), x_all.max(), 100) #grid of X values for smooth line

# For multivariate model, we need values for ALL features.
# We'll fix other features at their mean and vary only feature_to_plot.
X_mean = X_subset.mean()

X_grid = pd.DataFrame(
    np.repeat(X_mean.values.reshape(1, -1), repeats=len(x_grid), axis=0),
    columns=X_subset.columns
)
X_grid[feature_to_plot] = x_grid

# Predict using tuned baseline model
y_grid_pred = best_baseline_model.predict(X_grid)

# Plot scatter of actual data and regression line
plt.figure(figsize=(7, 5))
plt.scatter(x_all, y_all, alpha=0.7, label="Actual (Weight)")
plt.plot(x_grid, y_grid_pred, linewidth=2, label="Tuned Baseline Linear (Regression line)")

plt.xlabel(feature_to_plot)
plt.ylabel("Weight")
plt.title(f"Regression line of tuned Baseline Linear model\nTarget: Weight vs {feature_to_plot}")
plt.legend()
plt.tight_layout()
plt.show()